{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 101: from Zero to Hero\n",
    "\n",
    "# Introduction\n",
    "\n",
    "# Chapter 1: Installation and API keys\n",
    "\n",
    "!pip install langchain==0.0.208 deeplake openai==0.27.8 tiktoken\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR-OPENAI-API-KEY>\"\n",
    "\n",
    "# Chapter 2: The LLMs\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the \"OPENAI_API_KEY\" environment variable.\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\n",
    "\n",
    "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
    "print(llm(text))\n",
    "\n",
    "# Chapter 3: The Chains\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "   input_variables=[\"product\"],\n",
    "   template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"eco-friendly water bottles\"))\n",
    "\n",
    "# Chapter 4: The Memory\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "conversation = ConversationChain(\n",
    "   llm=llm,\n",
    "   verbose=True,\n",
    "   memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "conversation.predict(input=\"Tell me about yourself.\")\n",
    "\n",
    "# Continue the conversation\n",
    "conversation.predict(input=\"What can you do?\")\n",
    "conversation.predict(input=\"How can you help me with data analysis?\")\n",
    "\n",
    "# Display the conversation\n",
    "print(conversation)\n",
    "\n",
    "# Chapter 5: Deep Lake VectorStore\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Before executing the following code, make sure to have your\n",
    "# Activeloop key saved in the \"ACTIVELOOP_TOKEN\" environment variable.\n",
    "\n",
    "# instantiate the LLM and embeddings models\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# create our documents\n",
    "texts = [\n",
    "   \"Napoleon Bonaparte was born in 15 August 1769\",\n",
    "   \"Louis XIV was born in 5 September 1638\"\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"<YOUR-ACTIVELOOP-ORG-ID>\"\n",
    "my_activeloop_dataset_name = \"langchain_course_from_zero_to_hero\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "   llm=llm,\n",
    "   chain_type=\"stuff\",\n",
    "   retriever=db.as_retriever()\n",
    ")\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [\n",
    "   Tool(\n",
    "       name=\"Retrieval QA System\",\n",
    "       func=retrieval_qa.run,\n",
    "       description=\"Useful for answering questions.\"\n",
    "   ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "   tools,\n",
    "   llm,\n",
    "   agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "   verbose=True\n",
    ")\n",
    "\n",
    "response = agent.run(\"When was Napoleone born?\")\n",
    "print(response)\n",
    "\n",
    "# load the existing Deep Lake dataset and specify the embedding function\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# create new documents\n",
    "texts = [\n",
    "   \"Lady Gaga was born in 28 March 1986\",\n",
    "   \"Michael Jeffrey Jordan was born in 17 February 1963\"\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)\n",
    "\n",
    "# instantiate the wrapper class for GPT3\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "# create a retriever from the db\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "   llm=llm, chain_type=\"stuff\", retriever=db.as_retriever()\n",
    ")\n",
    "\n",
    "# instantiate a tool that uses the retriever\n",
    "tools = [\n",
    "   Tool(\n",
    "       name=\"Retrieval QA System\",\n",
    "       func=retrieval_qa.run,\n",
    "       description=\"Useful for answering questions.\"\n",
    "   ),\n",
    "]\n",
    "\n",
    "# create an agent that uses the tool\n",
    "agent = initialize_agent(\n",
    "   tools,\n",
    "   llm,\n",
    "   agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "   verbose=True\n",
    ")\n",
    "\n",
    "response = agent.run(\"When was Michael Jordan born?\")\n",
    "print(response)\n",
    "\n",
    "# Chapter 6: Agents in LangChain\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "# remember to set the environment variables\n",
    "# \"GOOGLE_API_KEY\" and \"GOOGLE_CSE_ID\" to be able to use\n",
    "# Google Search via API.\n",
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "   Tool(\n",
    "       name = \"google-search\",\n",
    "       func=search.run,\n",
    "       description=\"useful for when you need to search google to answer questions about current events\"\n",
    "   )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tools,\n",
    "                        llm,\n",
    "                        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                        verbose=True,\n",
    "                        max_iterations=6)\n",
    "\n",
    "response = agent(\"What's the latest news about the Mars rover?\")\n",
    "print(response['output'])\n",
    "\n",
    "# Chapter 7: Tools in LangChain\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "   input_variables=[\"query\"],\n",
    "   template=\"Write a summary of the following text: {query}\"\n",
    ")\n",
    "\n",
    "summarize_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# remember to set the environment variables\n",
    "# \"GOOGLE_API_KEY\" and \"GOOGLE_CSE_ID\" to be able to use\n",
    "# Google Search via API.\n",
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "   Tool(\n",
    "       name=\"Search\",\n",
    "       func=search.run,\n",
    "       description=\"useful for finding information about recent events\"\n",
    "   ),\n",
    "   Tool(\n",
    "      name='Summarizer',\n",
    "      func=summarize_chain.run,\n",
    "      description='useful for summarizing texts'\n",
    "   )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "   tools,\n",
    "   llm,\n",
    "   agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "   verbose=True\n",
    ")\n",
    "\n",
    "response = agent(\"What's the latest news about the Mars rover? Then please summarize the results.\")\n",
    "print(response['output'])\n",
    "\n",
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
